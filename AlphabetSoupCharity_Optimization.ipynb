{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "97jn3pflxJq8",
    "outputId": "b77fad34-5cbc-4fcb-c683-cd80d131b183"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt-get' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: Error opening archive: Failed to open '$SPARK_VERSION-bin-hadoop2.7.tgz'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Unable to find py4j in /content/spark-3.2.3-bin-hadoop2.7\\python, your SPARK_HOME may not be configured correctly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\findspark.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0mpy4j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lib\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"py4j-*.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14220\\1095360861.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Start a SparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mfindspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\findspark.py\u001b[0m in \u001b[0;36minit\u001b[1;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mpy4j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"lib\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"py4j-*.zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             raise Exception(\n\u001b[0m\u001b[0;32m    162\u001b[0m                 \"Unable to find py4j in {}, your SPARK_HOME may not be configured correctly\".format(\n\u001b[0;32m    163\u001b[0m                     \u001b[0mspark_python\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Unable to find py4j in /content/spark-3.2.3-bin-hadoop2.7\\python, your SPARK_HOME may not be configured correctly"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Find the latest version of spark 3.2 from http://www.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.2.3'\n",
    "spark_version = 'spark-3.2.3'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ye8tcnY7xfI8",
    "outputId": "5b4ea91f-88ab-4aea-e96d-c153cabc30dc"
   },
   "outputs": [],
   "source": [
    "#mount the content gdrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "uGMZ8iIKxjZ9",
    "outputId": "d50f207c-85b3-45d0-ca60-fa3c437d3501"
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "bpwhKFxixjdW",
    "outputId": "c4544a1a-3167-4849-efc5-214909fd3607"
   },
   "outputs": [],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df=application_df.drop([\"EIN\"],1)\n",
    "\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hP7_dv3Lxjhw",
    "outputId": "1ad08592-7fbe-4378-eadf-b2cc74c228ac"
   },
   "outputs": [],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.apply(lambda x:x.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iny82_RFxjkJ",
    "outputId": "7b36fcf4-5eb4-49ff-88dd-e3899ca16401"
   },
   "outputs": [],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "name_count =application_df[\"NAME\"].value_counts()\n",
    "name_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "bKaWOwNnxjnp",
    "outputId": "2d1fff9b-e2ac-43b0-b244-26bd962785ee"
   },
   "outputs": [],
   "source": [
    "# Visualize the value counts of APPLICATION_TYPE\n",
    "name_count.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2ZIUXTVxfLI",
    "outputId": "13df318a-fd1e-4a12-bcb1-2ab04994a0ef"
   },
   "outputs": [],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "replace_name = list(name_count[name_count<5].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for name in replace_name:\n",
    "    application_df.NAME = application_df.NAME.replace(name,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.NAME.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W_aOHJYncsS3",
    "outputId": "975e271f-2ab1-4984-baaa-4a038b99ad67"
   },
   "outputs": [],
   "source": [
    "#\n",
    "application_count = application_df[\"APPLICATION_TYPE\"].value_counts()\n",
    "application_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rnSrbdk4csai",
    "outputId": "81956c0b-10df-4dcd-aa61-6ab93b353949"
   },
   "outputs": [],
   "source": [
    "#replace application_type\n",
    "replace_app_count =  list(application_count[application_count<500].index)\n",
    "replace_app_count\n",
    "\n",
    "#replace dataframe\n",
    "for app in replace_app_count:\n",
    "  application_df.APPLICATION_TYPE = application_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "\n",
    "#check is binning is successful or not\n",
    "application_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6gvO1bnB0ib1",
    "outputId": "cab34fe2-1aeb-4e3a-d596-59b6b9163752"
   },
   "outputs": [],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "classification_count = application_df.CLASSIFICATION.value_counts()\n",
    "classification_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvn_LpJJgROf",
    "outputId": "856eeb51-2d12-443c-fdf8-b951981180a9"
   },
   "outputs": [],
   "source": [
    "replace_cls = classification_count[classification_count >1]\n",
    "replace_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDd0Ikvh0imL",
    "outputId": "69fa274e-28ca-4409-c212-e67885f2dfde"
   },
   "outputs": [],
   "source": [
    "# Determine which values to replace if counts are less than ..?\n",
    "replace_class =list(classification_count[classification_count <100].index)\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    application_df.CLASSIFICATION = application_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QEQpQThXIht3",
    "outputId": "be6c3403-2358-4281-ec60-cb17d7e2586c"
   },
   "outputs": [],
   "source": [
    "application_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ww0Osr7jAeF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9cNhSg_V0ipi",
    "outputId": "e7343c99-eada-44d9-a560-69465f0b6f96"
   },
   "outputs": [],
   "source": [
    "# Generate our categorical variable lists\n",
    "app_cat = application_df.dtypes[application_df.dtypes == \"object\"].index.tolist()\n",
    "application_df[app_cat].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "F7azKMxOxfOi",
    "outputId": "7fcd6488-7e61-4c6d-8ab5-2675c4c8de66"
   },
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(application_df[app_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(app_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "JjoaAl_HI6PX",
    "outputId": "14231998-35ef-4333-8a84-6affc2f013f9"
   },
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "new_df = application_df.merge(encode_df,left_index = True,right_index = True)\n",
    "new_df = new_df.drop(app_cat,1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TjjeNciI6Rv",
    "outputId": "2dae0465-86f2-4c06-f098-7ff50d298dc0"
   },
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = new_df[\"IS_SUCCESSFUL\"].values\n",
    "X = new_df.drop([\"IS_SUCCESSFUL\"],1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6Ag-E_oI6UL"
   },
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "amrK8hlYI6XZ",
    "outputId": "10bc9f8d-efdd-46da-97d0-39368940ed34"
   },
   "outputs": [],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 7\n",
    "hidden_nodes_layer2 = 14\n",
    "hidden_nodes_layer3 = 21\n",
    "\n",
    "nn_new = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_new.add(tf.keras.layers.Dense(units=hidden_nodes_layer1,input_dim=number_input_features,activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_new.add(tf.keras.layers.Dense(units=hidden_nodes_layer2,activation = \"sigmoid\"))\n",
    "\n",
    "# Output layer\n",
    "nn_new.add(tf.keras.layers.Dense(units=1,activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5rIeFLI5K7sE"
   },
   "outputs": [],
   "source": [
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints_optimized_v3/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints_optimized_v3/weights.{epoch:02d}.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JhT0NDOKLl2"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_new.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkaNCWwXKLuI"
   },
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zt7mKr9jKjmH",
    "outputId": "7cd7b42d-0050-4c71-8fc1-8a28d4096309"
   },
   "outputs": [],
   "source": [
    "#train the data\n",
    "fit_model = nn_new.fit(X_train_scaled,y_train,epochs=5,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gSyrCG4AKjpj"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn_new.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FpTE13VoLx15",
    "outputId": "8432a93a-5324-494e-a6c3-036c6e1f025f"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_loss, model_accuracy = nn_new.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "8RmsEaWDLx5T",
    "outputId": "fe1ff90d-0408-40e4-ed50-56d841d7b805"
   },
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "from google.colab import files\n",
    "\n",
    "nn_new.save('/content/AlphabetSoupCharity.h5')\n",
    "files.download('/content/AlphabetSoupCharity.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pIfm-MPDlTl3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
